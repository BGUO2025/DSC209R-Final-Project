# -*- coding: utf-8 -*-
"""California heatmap ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ll49gluoK1tbJbnrsD0F7c6DXtwnXNLJ
"""

import os, glob, re
from pathlib import Path
import pandas as pd
import folium
from folium.plugins import HeatMapWithTime

# === Inputs (includes your uploaded files) ===
PREFERRED_FILES = [
    Path("/mnt/data/usgs_main.csv"),
    Path("/mnt/data/usgs_current.csv"),
    Path("/mnt/data/usgs_california_combined.csv"),  # ok if missing
]

HEAT_RADIUS = 18
TIME_GRANULARITY = "auto"

OUT_HTML = Path("california_earthquakes_heatmap_animated.html")
OUT_USED_CSV = Path("california_earthquakes_used.csv")

# ---- Simple California polygon (lon, lat) ----
# A coarse but effective outline that follows CA borders; close enough for filtering out NV/AZ/OR.
# If you want stricter coastal inclusion, set INCLUDE_COASTAL_BAND=True below.
CALIFORNIA_POLY = [
    (-124.45,  42.00),  # NW near OR
    (-123.90,  41.50),
    (-120.00,  41.99),  # NV border line
    (-119.99,  39.00),
    (-120.00,  38.50),
    (-120.00,  38.00),
    (-119.75,  37.00),
    (-119.50,  36.50),
    (-119.00,  36.00),
    (-118.35,  35.00),
    (-117.00,  35.00),
    (-116.50,  34.80),
    (-115.50,  34.50),
    (-114.72,  34.75),
    (-114.48,  34.30),
    (-114.47,  34.00),
    (-114.64,  33.40),
    (-114.72,  32.72),  # SE corner near AZ/MX
    (-117.12,  32.53),  # San Diego coast
    (-118.70,  33.50),  # offshore around Channel Islands (rough)
    (-120.50,  34.70),
    (-122.00,  37.00),
    (-123.00,  38.70),
    (-124.00,  40.50),
    (-124.45,  42.00)   # close polygon
]

INCLUDE_COASTAL_BAND = True  # include a slim offshore rectangle
COASTAL_BAND = [  # lon/lat rectangle just off the coast (optional)
    (-125.2, 32.4), (-125.2, 42.2), (-124.3, 42.2), (-124.3, 32.4), (-125.2, 32.4)
]

# --- Utilities ---
def find_usgs_csvs():
    files = [p for p in PREFERRED_FILES if p.is_file()]
    if files:
        return files
    # Fallback search
    candidates = [Path(p) for p in glob.glob("**/*.csv", recursive=True)
                  if "usgs" in Path(p).name.lower()]
    candidates.sort()
    files, seen = [], set()
    for p in candidates:
        rp = p.resolve()
        if rp not in seen and p.is_file():
            files.append(p); seen.add(rp)
    return files

def read_csv_robust(path: Path):
    last_err = None
    for enc in ("utf-8", "utf-8-sig", "latin-1"):
        try:
            return pd.read_csv(path, encoding=enc, engine="python", on_bad_lines="skip")
        except Exception as e:
            last_err = e
    raise RuntimeError(f"Failed to read {path} — last error: {last_err}")

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    colmap = {c.lower(): c for c in df.columns}
    lat_col = colmap.get("latitude") or colmap.get("lat")
    lon_col = colmap.get("longitude") or colmap.get("lon") or colmap.get("long")
    time_col = colmap.get("time") or colmap.get("timestamp") or colmap.get("date")
    mag_col  = colmap.get("mag") or colmap.get("magnitude")
    place_col = colmap.get("place")

    missing = [name for name, col in {"latitude": lat_col, "longitude": lon_col, "time": time_col}.items() if not col]
    if missing:
        raise KeyError(f"Missing required columns: {missing}. Found: {list(df.columns)[:12]}")

    cols = [time_col, lat_col, lon_col] + ([mag_col] if mag_col else []) + ([place_col] if place_col else [])
    out = df[cols].copy()
    out.columns = ["time", "lat", "lon"] + (["mag"] if mag_col else []) + (["place"] if place_col else [])
    out["time"] = pd.to_datetime(out["time"], errors="coerce", utc=True)
    out["lat"]  = pd.to_numeric(out["lat"], errors="coerce")
    out["lon"]  = pd.to_numeric(out["lon"], errors="coerce")
    out = out.dropna(subset=["time", "lat", "lon"]).reset_index(drop=True)
    return out

def fix_western_hemisphere_lons(df: pd.DataFrame) -> pd.DataFrame:
    # If most longitudes are positive in CA-range, flip them negative
    lon = df["lon"].dropna()
    frac_pos_west = (lon.between(114, 125)).mean()
    if frac_pos_west >= 0.6:
        df.loc[df["lon"].between(114, 125), "lon"] = -df.loc[df["lon"].between(114, 125), "lon"]
    return df

def point_in_polygon(lon: float, lat: float, poly):
    """Ray casting algorithm to test (lon, lat) inside polygon of [(lon,lat), ...]."""
    inside = False
    n = len(poly)
    for i in range(n):
        x1, y1 = poly[i]
        x2, y2 = poly[(i + 1) % n]
        # Check if point crosses edge
        cond = ((y1 > lat) != (y2 > lat))
        if cond:
            x_at_y = (x2 - x1) * (lat - y1) / (y2 - y1 + 1e-12) + x1
            if lon < x_at_y:
                inside = not inside
    return inside

def in_ca_state(lon, lat):
    if point_in_polygon(lon, lat, CALIFORNIA_POLY):
        return True
    if INCLUDE_COASTAL_BAND and point_in_polygon(lon, lat, COASTAL_BAND):
        return True
    return False

def choose_granularity(df: pd.DataFrame, mode: str):
    if mode != "auto":
        return mode
    span_days = int((df["time"].max() - df["time"].min()).days)
    if span_days <= 31: return "daily"
    if span_days <= 180: return "weekly"
    return "monthly"

def build_period(df: pd.DataFrame, granularity: str):
    if granularity == "daily":
        df["period"] = df["time"].dt.floor("D"); label_fmt = "%Y-%m-%d"
    elif granularity == "weekly":
        df["period"] = df["time"].dt.to_period("W-MON").apply(lambda r: r.start_time); label_fmt = "Week of %Y-%m-%d"
    else:
        df["period"] = df["time"].dt.to_period("M").apply(lambda r: r.start_time); label_fmt = "%Y-%m"
    return df, label_fmt

def main():
    files = find_usgs_csvs()
    if not files:
        raise FileNotFoundError("No USGS CSVs found.")
    print("Reading CSVs:")
    for f in files:
        print("  -", f)

    dfs = [normalize_cols(read_csv_robust(f)) for f in files]
    raw = pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0].copy()
    raw = fix_western_hemisphere_lons(raw)

    # --- State-accurate filter: keep only points inside California polygon (+ optional coastal band)
    ca_mask = raw.apply(lambda r: in_ca_state(float(r["lon"]), float(r["lat"])), axis=1)
    df_ca = raw[ca_mask].copy()

    print(f"Rows total: {len(raw)} | In-California: {len(df_ca)}")
    if df_ca.empty:
        lon_desc = raw["lon"].describe().to_string()
        print("Longitude describe():\n", lon_desc)
        raise ValueError("No rows are inside California polygon. Check longitude signs or adjust polygon.")

    # Heat weights
    if "mag" in df_ca.columns:
        mag = df_ca["mag"].clip(lower=0, upper=9).fillna(0)
        df_ca["weight"] = (mag / 9).pow(1.5) * 0.8 + 0.2
    else:
        df_ca["weight"] = 0.6

    # Time grouping
    gran = choose_granularity(df_ca, TIME_GRANULARITY)
    df_ca, label_fmt = build_period(df_ca, gran)

    # Frames for HeatMapWithTime
    frames, labels = [], []
    for t, g in df_ca.sort_values("period").groupby("period"):
        frame = g[["lat", "lon", "weight"]].values.tolist()
        if frame:
            frames.append(frame)
            labels.append(t.strftime(label_fmt))

    # Map
    m = folium.Map(location=[37.0, -120.0], zoom_start=6, tiles="cartodbpositron", control_scale=True)
    HeatMapWithTime(
        data=frames,
        index=labels,
        auto_play=True,
        max_opacity=0.9,
        radius=HEAT_RADIUS,
        use_local_extrema=False,
        min_opacity=0.2
    ).add_to(m)

    title_html = f"""
    <div style="position: fixed; top: 10px; left: 50%; transform: translateX(-50%);
    background: rgba(255,255,255,0.9); padding: 8px 12px; border-radius: 8px;
    font-family: system-ui, -apple-system, Segoe UI, Roboto, 'Helvetica Neue', Arial; font-size: 14px;">
    <b>California Earthquakes — Animated Heatmap</b>
    <span style="margin-left:8px; color:#666;">(granularity: {gran}; radius: {HEAT_RADIUS})</span>
    </div>
    """
    m.get_root().html.add_child(folium.Element(title_html))

    # Save
    m.save(OUT_HTML.as_posix())
    df_ca_out = df_ca[["time", "lat", "lon"] + (["mag"] if "mag" in df_ca.columns else []) + ["weight", "period"]].sort_values("time")
    df_ca_out.to_csv(OUT_USED_CSV, index=False)

    print(f"✅ Saved animation → {OUT_HTML.resolve()}")
    print(f"✅ Saved filtered data → {OUT_USED_CSV.resolve()}")
    print(f"Rows used: {len(df_ca_out)} | Periods: {len(labels)} | Granularity: {gran}")

if __name__ == "__main__":
    main()

from google.colab import files
files.download("california_earthquakes_heatmap_animated.html")